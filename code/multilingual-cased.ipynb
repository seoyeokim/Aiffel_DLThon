{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(data_name):\n",
    "    data_path = os.getenv('HOME')+'/aiffel/project_data/dlthon/'+data_name\n",
    "    imported_data = pd.read_csv(data_path)\n",
    "    return imported_data\n",
    "\n",
    "def cleaning_sentence(sentence):\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "        sentence = re.sub(r'\\([^)]*\\)', '', sentence)\n",
    "        sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "        sentence = re.sub(\"[^가-힣a-zA-Z0-9\\.\\?\\!,]+\", \" \", sentence)\n",
    "        sentence = re.sub(r'[\\n\\r]+', ' ', sentence)\n",
    "        sentence = sentence.strip()\n",
    "        return sentence\n",
    "\n",
    "def preprocess_sentence(data_list):\n",
    "    retrun_list = []\n",
    "    for sentence_frame in data_list:\n",
    "         befor_df = {}\n",
    "         conv_data = []\n",
    "         class_data = []\n",
    "         class_name = sentence_frame['class'][0]\n",
    "         for sentence in sentence_frame['conversation']:\n",
    "             cleaned_sentence = cleaning_sentence(sentence)\n",
    "             conv_data.append(cleaned_sentence)\n",
    "             class_data.append(class_name)\n",
    "         return_df = pd.DataFrame({'class' : class_data, 'conversation': conv_data})\n",
    "         retrun_list.append(return_df)\n",
    "    return retrun_list\n",
    "\n",
    "def random_deletion(text, prob=0.2):\n",
    "    words = text.split()\n",
    "    if len(words) == 1:\n",
    "        return text\n",
    "    return ' '.join([word for word in words if random.random() > prob])\n",
    "\n",
    "def random_swap(text, n=1):\n",
    "    words = text.split()\n",
    "    for _ in range(n):\n",
    "        idx1, idx2 = random.sample(range(len(words)), 2)\n",
    "        words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def convert_label(data):\n",
    "    label_map = {'협박 대화': 0, '갈취 대화': 1, '직장 내 괴롭힘 대화': 2, '기타 괴롭힘 대화': 3, '일반 대화': 4}\n",
    "    \n",
    "    data['class'] = data['class'].map(label_map)\n",
    "    return data\n",
    "\n",
    "def cal_len(train, test, rate):\n",
    "    con_data = np.concatenate((train, test), axis = 0)\n",
    "    seg_len = []\n",
    "    spl_len = []\n",
    "    for i in con_data:\n",
    "        single_seg_len = len(i)\n",
    "        seg_len.append(single_seg_len)\n",
    "    for i in con_data:\n",
    "        single_spl_len = len(i.split())\n",
    "        spl_len.append(single_spl_len)\n",
    "    spl_len.sort()\n",
    "    seg_len.sort()\n",
    "    print('spl len is : ', spl_len[int(len(spl_len)*rate)])\n",
    "    print('seg len is : ', seg_len[int(len(seg_len)*rate)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(data_list, prob, n):\n",
    "    len_data = []\n",
    "\n",
    "    for data in data_list:\n",
    "        len_data.append(len(data))\n",
    "\n",
    "    max_len_of = max(len_data)\n",
    "\n",
    "    return_data = []\n",
    "\n",
    "    for data_set in data_list:\n",
    "        if len(data_set) != max_len_of:\n",
    "            conver_data = []\n",
    "            class_Data = []\n",
    "            return_df = {}\n",
    "            aug_len = max_len_of - len(data_set)\n",
    "            class_name = data_set['class'][0]\n",
    "            for i in range(aug_len): class_Data.append(class_name)\n",
    "            for i in range(aug_len):\n",
    "                choice_num = random.random()\n",
    "                random_seq = data_set['conversation'].sample(1).iloc[0]\n",
    "                if choice_num >= 0.5:\n",
    "                    output_seq = random_deletion(random_seq, prob)\n",
    "                    conver_data.append(output_seq)\n",
    "                else:\n",
    "                    output_seq = random_swap(random_seq, n)\n",
    "                    conver_data.append(output_seq)\n",
    "                    \n",
    "            retrun_df = pd.DataFrame({'class':class_Data, 'conversation':conver_data})\n",
    "        else:\n",
    "            retrun_df = 0\n",
    "\n",
    "        return_data.append(retrun_df)\n",
    "\n",
    "    final_list = []\n",
    "\n",
    "    for auged_data, real_data in zip(return_data, data_list):\n",
    "        if isinstance(auged_data, pd.DataFrame):\n",
    "            real_data = pd.concat([real_data, auged_data])\n",
    "            real_data.reset_index(drop=True, inplace=True)\n",
    "            final_list.append(real_data)\n",
    "        else:\n",
    "            final_list.append(real_data)\n",
    "    \n",
    "    return final_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3967076780b54ba182dc25d4ccfecf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ad22e49a004e3dbc1193bc26288f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/449M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59a98ee237843eeaf2974f30d4590c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd540970ab54e7faacf70fcb8dd8074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723e27ed1bf1426aa1c188d454a3d2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_model = TFAutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(datas, sent_max_length):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for sent in datas:\n",
    "        encoded = tokenizer.encode_plus(sent,\n",
    "                                        add_special_tokens = True,\n",
    "                                        max_length = sent_max_length,\n",
    "                                        padding='max_length',\n",
    "                                        truncation = True,\n",
    "                                        return_attention_mask=True)\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids), np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(bert_model, max_len):\n",
    "    input_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32)\n",
    "    attention_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32)\n",
    "    \n",
    "    output = bert_model([input_ids, attention_mask])\n",
    "    output = output.last_hidden_state\n",
    "    output = tf.keras.layers.Dense(64, activation='relu')(output)\n",
    "    output = tf.keras.layers.Dropout(0.2)(output)\n",
    "    output = tf.keras.layers.Dense(3, activation='softmax')(output)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = [input_ids, attention_mask], outputs = output)\n",
    "    model.compile(Adam(learning_rate=0.0001),loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_import('train.csv')\n",
    "nomal_data = data_import('nomal_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(train_data.columns[0], axis=1)\n",
    "threat_data = train_data[train_data['class'] == '협박 대화']\n",
    "extort_data = train_data[train_data['class'] == '갈취 대화']\n",
    "co_bully_data = train_data[train_data['class'] == '직장 내 괴롭힘 대화']\n",
    "bully_data = train_data[train_data['class'] == '기타 괴롭힘 대화']\n",
    "\n",
    "threat_data.reset_index(drop=True, inplace=True)\n",
    "extort_data.reset_index(drop=True, inplace=True)\n",
    "co_bully_data.reset_index(drop=True, inplace=True)\n",
    "bully_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "k = []\n",
    "for i in range(nomal_data.shape[0]): k.append('일반 대화')\n",
    "nomal_data['class'] = k\n",
    "nomal_data = nomal_data.rename(columns={'0':'conversation'})\n",
    "nomal_data = nomal_data[['class', 'conversation']]\n",
    "nomal_data = nomal_data.sample(3000)\n",
    "nomal_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [nomal_data, threat_data, extort_data, co_bully_data, bully_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>카드 결제되나요?\\n그럼요. 카드 결제 가능하세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>가게 문 언제까지 하는데요?\\n6시 반까지해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>오뎅 국물은 이걸로 뜨나요?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>이 가방은 얼마예요?\\n이 가방은 오만 오천 원이에</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>여기는 몇 시에 문 열어요?\\n열한시 반에 열어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>리필 심을 다 쓰면?\\n리필 심이 따로 나와서 갈아 끼우시면 돼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>식빵 다 나갔나요?\\n네, 오늘 식빵이 빨리 빠졌어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>고기를 검은 비닐봉지에 담아 주실 수 있나요?\\n네, 다른 건 필요 없으세요?\\n현...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>냉장보관 해야하나요?\\n냉동실에 보관하시고 당일에 꺼내 냉장으로 옮기셔야 합니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>이쁘네요 근데 좀 더 촉촉했으면 좋겠어요\\n립글로스 계열이 좋아</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                       conversation\n",
       "0     일반 대화                        카드 결제되나요?\\n그럼요. 카드 결제 가능하세요\n",
       "1     일반 대화                           가게 문 언제까지 하는데요?\\n6시 반까지해\n",
       "2     일반 대화                                  오뎅 국물은 이걸로 뜨나요?\\n\n",
       "3     일반 대화                       이 가방은 얼마예요?\\n이 가방은 오만 오천 원이에\n",
       "4     일반 대화                         여기는 몇 시에 문 열어요?\\n열한시 반에 열어\n",
       "...     ...                                                ...\n",
       "2995  일반 대화                리필 심을 다 쓰면?\\n리필 심이 따로 나와서 갈아 끼우시면 돼\n",
       "2996  일반 대화                       식빵 다 나갔나요?\\n네, 오늘 식빵이 빨리 빠졌어\n",
       "2997  일반 대화  고기를 검은 비닐봉지에 담아 주실 수 있나요?\\n네, 다른 건 필요 없으세요?\\n현...\n",
       "2998  일반 대화       냉장보관 해야하나요?\\n냉동실에 보관하시고 당일에 꺼내 냉장으로 옮기셔야 합니다\n",
       "2999  일반 대화                이쁘네요 근데 좀 더 촉촉했으면 좋겠어요\\n립글로스 계열이 좋아\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_data = pd.concat(data_list, axis = 0)\n",
    "\n",
    "proto_data = np.array(proto_data['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_data = []\n",
    "\n",
    "for sentence in proto_data:\n",
    "    sentence = re.sub(r'\\n', ' 옌 ', sentence)\n",
    "    changed_data.append(sentence)\n",
    "\n",
    "prot_data = np.array(changed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['카드 결제되나요? 옌 그럼요. 카드 결제 가능하세요', '가게 문 언제까지 하는데요? 옌 6시 반까지해',\n",
       "       '오뎅 국물은 이걸로 뜨나요? 옌 ', ...,\n",
       "       '애들아 공연 연습하자. 옌 이번주에 최종 평가 있어. 빨리 하자. 옌 야 김정미 너는 왜 맨날 이 부분에서 틀려? 옌 어. 미안해 내가 더 연습해야 했는데 옌 너 때문에 동작이 하나도 안 맞잖아. 그리고 표정은 또 왜이렇게 어두워? 옌 미안해 다음부턴 웃으면서 할게 옌 춤에 소질이 없으면 그냥 팀에서 나가. 너 케어할 시간 없으니까 옌 미안해 내가 더 노력할게 옌 제발 민폐 좀 끼치지마 대체 춤에 뭐가 자신있다고 여기 들어온건지. 옌 알았어.',\n",
       "       '나를 왜 자꾸 때려 옌 때리고 싶으니깐. 옌 내가 뭐 잘못했어? 옌 아니 잘못없지 옌 근데 왜? 옌 너만보면 기분이 나쁘니깐 옌 왜 나쁜데 옌 쳐다보는게 기분나쁘다 옌 그럼 어떡해야해? 옌 그냥 닥치고 맞으면 돼',\n",
       "       '준하야 넌 대가리가 왜이렇게 크냐? 옌 내 머리가 뭐. 옌 밥먹으면 대가리만 크냐 너는? 옌 아니. 무슨 머리만 큰다고 그러는거야 옌 주위를 둘러봐라. 내가 살면서 너보다 큰 대가리를 못봤어. 옌 나한테 왜그러는거야. 옌 무식하게 대가리만 크면 뭐하냐? 멍청해가지고는 쯧쯧 옌 넌 내가 그렇게 싫니? 옌 당연하지. 언제 이 세상에서 없어지냐 너 내가 그날만 기다리고 있어 옌 조만간 사라져줄게 너 눈앞에서 옌 그거 요즘들은 소식중에 제일 좋은 소식이다.'],\n",
       "      dtype='<U896')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_a = np.array(prot_data[:int(0.8*len(prot_data))], dtype = str)\n",
    "test_data_a = np.array(prot_data[int(0.8*len(prot_data)):], dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spl len is :  240\n",
      "seg len is :  896\n"
     ]
    }
   ],
   "source": [
    "cal_len(train_data_a, test_data_a, 0.999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids_a, train_attention_mask_a = bert_encode(train_data_a, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 6, 246458, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode('옌'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0, 193757,  27940, 101359,   7214, 134556,   5144,     32,\n",
       "            6, 246458,    305,   2166,  20451,   7214,   1963,      2,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids_a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_laber(data, index_num, max_len):\n",
    "    return_data = []\n",
    "    \n",
    "    for conv in data:\n",
    "        config_num = 0\n",
    "        return_sigle_sent = []\n",
    "        for sen in conv:\n",
    "            if sen == index_num:\n",
    "                if config_num == 0:\n",
    "                    config_num = 1\n",
    "                else:\n",
    "                    config_num = 0\n",
    "            elif sen == 1:\n",
    "                return_sigle_sent.append(2)\n",
    "            else :\n",
    "                return_sigle_sent.append(config_num)\n",
    "        return_sigle_sent = np.array(return_sigle_sent)\n",
    "        if return_sigle_sent.shape[0] != max_len:\n",
    "            add_len = max_len - return_sigle_sent.shape[0]\n",
    "            num_in = return_sigle_sent[-1]\n",
    "            for i in range(add_len):\n",
    "                return_sigle_sent = np.append(return_sigle_sent, int(num_in))\n",
    "            return_sigle_sent = np.reshape(return_sigle_sent, (1, max_len))\n",
    "        return_data.append(return_sigle_sent)\n",
    "    \n",
    "    return return_data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_ids = make_laber(train_input_ids_a,246458, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_ids_np = np.concatenate(train_label_ids, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_ids_np[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_data = []\n",
    "\n",
    "for sentence in proto_data:\n",
    "    sentence = re.sub(r'[\\n\\r]+', ' ', sentence)\n",
    "    changed_data.append(sentence)\n",
    "\n",
    "proto_data = np.array(changed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_b = np.array(proto_data[:int(0.8*len(proto_data))], dtype = str)\n",
    "test_data_b = np.array(proto_data[int(0.8*len(proto_data)):], dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_input_ids_b, train_a_attention_mask_b = bert_encode(train_data_b, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0, 193757,  27940, 101359,   7214, 134556,   5144,     32,\n",
       "          305,   2166,  20451,   7214,   1963,      2,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_a_input_ids_b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_a_attention_mask_b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 240)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 240)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 117653760   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 240, 64)      24640       tf_bert_model[0][13]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 240, 64)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 240, 3)       195         dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 117,678,595\n",
      "Trainable params: 117,678,595\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "use_bert_model = create_model(bert_model, 240)\n",
    "use_bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "556/556 [==============================] - 129s 228ms/step - loss: 0.0417 - accuracy: 0.9828 - val_loss: 0.4795 - val_accuracy: 0.8408\n",
      "Epoch 2/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0372 - accuracy: 0.9847 - val_loss: 0.4603 - val_accuracy: 0.8462\n",
      "Epoch 3/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0325 - accuracy: 0.9868 - val_loss: 0.5043 - val_accuracy: 0.8464\n",
      "Epoch 4/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 0.4814 - val_accuracy: 0.8474\n",
      "Epoch 5/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0302 - accuracy: 0.9881 - val_loss: 0.5906 - val_accuracy: 0.8409\n",
      "Epoch 6/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0247 - accuracy: 0.9904 - val_loss: 0.6311 - val_accuracy: 0.8535\n",
      "Epoch 7/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0228 - accuracy: 0.9912 - val_loss: 0.6517 - val_accuracy: 0.8488\n",
      "Epoch 8/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0225 - accuracy: 0.9914 - val_loss: 0.5849 - val_accuracy: 0.8525\n",
      "Epoch 9/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0212 - accuracy: 0.9917 - val_loss: 0.6123 - val_accuracy: 0.8491\n",
      "Epoch 10/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0231 - accuracy: 0.9912 - val_loss: 0.5787 - val_accuracy: 0.8491\n",
      "Epoch 11/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0194 - accuracy: 0.9927 - val_loss: 0.6342 - val_accuracy: 0.8465\n",
      "Epoch 12/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.6915 - val_accuracy: 0.8494\n",
      "Epoch 13/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0150 - accuracy: 0.9943 - val_loss: 0.6041 - val_accuracy: 0.8477\n",
      "Epoch 14/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.6612 - val_accuracy: 0.8498\n",
      "Epoch 15/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 0.7201 - val_accuracy: 0.8402\n",
      "Epoch 16/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.6234 - val_accuracy: 0.8525\n",
      "Epoch 17/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0135 - accuracy: 0.9950 - val_loss: 0.7272 - val_accuracy: 0.8555\n",
      "Epoch 18/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.6635 - val_accuracy: 0.8398\n",
      "Epoch 19/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.7121 - val_accuracy: 0.8479\n",
      "Epoch 20/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.7243 - val_accuracy: 0.8505\n",
      "Epoch 21/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.6963 - val_accuracy: 0.8525\n",
      "Epoch 22/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.6276 - val_accuracy: 0.8522\n",
      "Epoch 23/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.8291 - val_accuracy: 0.8400\n",
      "Epoch 24/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.6716 - val_accuracy: 0.8550\n",
      "Epoch 25/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.5926 - val_accuracy: 0.8379\n",
      "Epoch 26/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.6996 - val_accuracy: 0.8518\n",
      "Epoch 27/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.8168 - val_accuracy: 0.8483\n",
      "Epoch 28/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.7652 - val_accuracy: 0.8501\n",
      "Epoch 29/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.6659 - val_accuracy: 0.8459\n",
      "Epoch 30/30\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.6994 - val_accuracy: 0.8506\n"
     ]
    }
   ],
   "source": [
    "history = use_bert_model.fit([train_a_input_ids_b, train_a_attention_mask_b], train_label_ids_np, validation_split=0.2, epochs = 30, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['저기 신입은 남자친구있어? 옌 아 없는데요 옌 그럼 저기 과장님어때? 옌 네? 저보다 20살 많으시지않나요 옌 뭐어때 돈만많음되지 잘해봐 옌 아 전 괜찮습니다 옌 에이 왜케 뻗대 주말에뭐해? 혼자 외롭잖아 옌 아.제 스타일이 아니셔셔요 옌 아 참 막내가 건방지게도 말하네 옌 죄송합니다.',\n",
       "       '조과장 이거 했어? 옌 아 아직 못했습니다 다른 일이 밀려서요 옌 조과장 뭐하는 사람이야? 휴 너 오늘 집 갈 생각 말고 밥도 먹지 말고 다해놔라 옌 네 이사님 옌 조과장은 할 줄 아는게 없어? 씨 욕나온다 옌 저도 하는데 일이 계속 터져서요 업무 분배해주시면 안될까요? 옌 분배? 조과장이 다해야지 누굴시켜? 내가하리? 옌 아.네 옌 제대로 해라 쫌 할 줄 아는게 뭔지 옌 네.',\n",
       "       '이거 누가 올린 보고서야!!! 옌 오늘 까지 올리라고 하셔서 제가 아침에 올려놨는데요. 옌 이게 최선이니? 넌 이렇게 밖에 못해? 옆에 있는 김대리랑 동기면서 차이 너무 나는거 아니니? 옌 .뭐가 잘못 됐을까요? 알려주시면 다시 작성해 오겠습니다. 옌 그걸 니가 알아서 해와야지 내가 일일이 그걸 다 알려줘야 하니? 옌 네. 다시 해오겠습니다. 옌 다들 점심먹으러 갑시다 너는 그거 수정해야 해서 점심 못먹지? 우리끼리 갔다올께 옌 네. 다녀오세요. 옌  옌 다했니? 점심도 안먹으면서 했는데도 아직도니? 옌 아네.곧 가져다 드릴께요.',\n",
       "       ...,\n",
       "       '애들아 공연 연습하자. 옌 이번주에 최종 평가 있어. 빨리 하자. 옌 야 김정미 너는 왜 맨날 이 부분에서 틀려? 옌 어. 미안해 내가 더 연습해야 했는데 옌 너 때문에 동작이 하나도 안 맞잖아. 그리고 표정은 또 왜이렇게 어두워? 옌 미안해 다음부턴 웃으면서 할게 옌 춤에 소질이 없으면 그냥 팀에서 나가. 너 케어할 시간 없으니까 옌 미안해 내가 더 노력할게 옌 제발 민폐 좀 끼치지마 대체 춤에 뭐가 자신있다고 여기 들어온건지. 옌 알았어.',\n",
       "       '나를 왜 자꾸 때려 옌 때리고 싶으니깐. 옌 내가 뭐 잘못했어? 옌 아니 잘못없지 옌 근데 왜? 옌 너만보면 기분이 나쁘니깐 옌 왜 나쁜데 옌 쳐다보는게 기분나쁘다 옌 그럼 어떡해야해? 옌 그냥 닥치고 맞으면 돼',\n",
       "       '준하야 넌 대가리가 왜이렇게 크냐? 옌 내 머리가 뭐. 옌 밥먹으면 대가리만 크냐 너는? 옌 아니. 무슨 머리만 큰다고 그러는거야 옌 주위를 둘러봐라. 내가 살면서 너보다 큰 대가리를 못봤어. 옌 나한테 왜그러는거야. 옌 무식하게 대가리만 크면 뭐하냐? 멍청해가지고는 쯧쯧 옌 넌 내가 그렇게 싫니? 옌 당연하지. 언제 이 세상에서 없어지냐 너 내가 그날만 기다리고 있어 옌 조만간 사라져줄게 너 눈앞에서 옌 그거 요즘들은 소식중에 제일 좋은 소식이다.'],\n",
       "      dtype='<U896')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a_input_ids, test_a_attention_mask = bert_encode(test_data_a, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_ids = make_laber(test_a_input_ids,246458, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_ids_np = np.concatenate(test_label_ids, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a_input_ids_b, test_a_attention_mask_b = bert_encode(test_data_b, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 9s 209ms/step - loss: 0.8876 - accuracy: 0.8139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8876399993896484, 0.8138608932495117]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_bert_model.evaluate([test_a_input_ids_b, test_a_attention_mask_b], test_label_ids_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
